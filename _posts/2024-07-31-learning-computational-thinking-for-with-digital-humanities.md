---
layout: post
title:  "Learning Computational Thinking for/with Digital Humanities"
author: "Evgeny Kuznetsov"
date:   2024-07-31
---

> This is an introductory post for a developing blogging project.


### Storytime

It’s 2013 and I’m living together with my best friend, a videogame designer, who decides to create a little scavenger hunt for me to play for my birthday. I’m having a blast solving puzzles, looking for clues, moving from one room to another emptying boxes and leafing through books, and then finally the finish line is in sight. As I unravel the final hint, which is supposed to point me towards my coveted prize (a Ubisoft realtone cable, so that I can finally play *Rocksmith*), a realization dawns on me: while I was at work, my roommate put my birthday present inside my PC tower. Now he’s watching me with playful delight: all I need to do is unscrew the side lid, reach in, take the cable, then put the lid back on and celebrate. A pretty straight-forward task, which I approach with all the skill and aplomb of someone completely confident in using digital technology: **I start crying**.

<!-- more -->

> My roommate is understandably taken aback by my reaction and tries to apologize without quite understanding what he is apologizing for, but he is hardly the most bewildered person in the room that day. I hadn’t done this mental math at the time, but over 10 years have passed since, allowing me to ponder.

I grew up in a family of two computer scientists, and was working at a tech start-up at the time, having graduated from a magnet high school that specialized in mathematics, and a university program in applied computational linguistics. Even though I always gravitated towards humanities disciplines, I felt confident around computers, and for some of my university colleagues with language studies backgrounds I looked like a full-on tech whiz during our coding classes. And yet, something about the idea of touching computer hardware in a way I was not “supposed to” left me completely paralyzed. A voice inside me, which I hadn’t even known existed before that encounter, insisted that such a task as unscrewing a lid off a PC case required arcane knowledge that I didn’t possess and could never hope to possess without extensive training.

Looking back, my reaction most likely originated with how differently I thought of *software* (as a creative and playful medium that various people, including myself, could produce new objects in), and of *hardware* (as a black-box consumer product that would perform an expected function if I operated it strictly within consumer guidelines). Having grown up alongside the Internet, and used to having to deal with clunky unwieldy systems if I wanted to fully participate in online life, I’d learned to approach software as something that could fail in unexpected ways at any point, but would rarely break down completely beyond repair. I’d learned, when one of these failures happened, to try to figure out **why** particular mistakes were happening, so that I could attempt to resolve them and avoid them in the future. In other words, the clunkiness and forced experimentation had taught me that software applications were human-made for particular purposes, with limited tools that were available to them, but not always best-suited for the job.

**Software was fallible** because of its human creators, and the failures were sometimes convoluted, but always ultimately understandable, if I could trace the logic of the people who made it, or came up with a good question to ask others. Hardware, by contrast, was something I had at home and in school, and had to learn how to **operate “properly,”** but wasn’t allowed to explore or tinker with. I could be a tinkerer with software, because I understood it was made by tinkerers, to be tinkered with. And, because I was taught that hardware was something I needed to press the right buttons on, so that a particular picture was displayed on the screen, I understood only that I could **“break everything”** if I pressed these buttons wrong.

<br>  

### The Problem

Eleven years after my encounter with the mortifying task of reaching inside a computer, I’ve both tried to bring my own understanding of hardware closer to the creative tinkering perspective I’ve enjoyed towards software since a pretty young age, and taken up opportunities to teach coding and digital literacy to others, largely people of (even) less technical backgrounds than my own. Throughout this, I’ve discovered two things, both of which I find increasingly concerning:

1. There is a plethora of playful complete-beginner introductions to how computers work -- but they are all aimed at kids. There are, of course, also lots of resources for adults -- but they expect an audience of people with a professional interest in computing science (such as, for example, future highly specialized IT workers). There are hardly any materials teaching the fundamentals of physical computing to adults from non-technical backgrounds, like myself.

2. The consumer-goods perspective that I discovered I held towards hardware has been steadily permeating the teaching of digital literacy and even coding as well. An entire generation of educators has relied on the myth of “digital natives” -- young people who grow up alongside digital technology -- organically picking the tinkering orientation towards software up just by virtue of having been born into a world where digital technology is ubiquitous. Rather than this utopian picture, more and more software that we rely on for our everyday life is becoming blackboxed from its users, encouraging people interacting with digital technology to trust the process and learn the “correct” button presses, instead of exploring how digital technology is made, with what tools, and for what purpose.

In both my teaching practice and my academic work I frequently encounter folks who struggle with technical aspects of coding and design, or misapply particular humanities methods and methodologies in the study of certain technologies (such as video games), because they come to this research or learning with incorrect assumptions about how computers work. At the same time, computers and the internet have become such a ubiquitous part of our technological world that widespread fundamental misunderstandings of how they function can become dangerous if left unaddressed, especially considering that commercial companies that develop many of the technologies we use every day have a vested interest in keeping users in the dark, making us more dependent on commercial solutions.

<br>

### What to do?

Certainly, there is no silver bullet solution to these issues, whose roots run deep and reach far. But the way I’ve been trying to tackle them for myself is through interdisciplinary self-education on computational thinking. Even though my intuition tells me hardware is sacred and ineffable, historical methods found in Digital Humanities research remind me instead that all hardware was designed by humans for humans, with particular purpose in mind, and particular sociocultural forces shaping the development context. As I’m exploring these contexts for myself, I’m accumulating references, resources and my own long-standing misunderstandings that these explorations help straighten out.

Recently the number of these reached such a critical point that I’ve started pondering how to share them with others, perhaps helping people with similar backgrounds shift their own perspectives, and then educate more of their peers in turn. With this particular project, I’m interested in exploring avenues to teaching computation, computer literacy and algorithmic thinking that would be grounded in critical digital humanities theories and would take a historical and cultural studies approach to talking about digital technology, instead of focusing on practical applications and “trainable” skills. I would like to try to design a curriculum (or, more realistically, the beginnings of a draft of a curriculum, to distribute in open access and allow other people to contribute to) for teaching these ideas to people interested in digital humanities and digital scholarship. This post is the first step towards making these materials and ideas public, and asking you all for co-participation.

<br>

### "Stupid questions" box

The main way I learn is through asking “silly” questions and then obsessively researching answers to them. This method served me particularly well with computer literacy, where I (like many others) have a lot of personal intuitive experience with computer hardware, and have learned numerous metaphors through pop-cultural osmosis, but often lack context for an in-depth understanding of where and how these ubiquitous concepts originated. I also find that paying close attention to how we talk about computers can help us spot common misconceptions and misunderstandings rooted in discursive traditions.

Because of this, one of the avenues for crowd-sourcing materials for this project for me has been opening a “stupid questions about computers that you’ve always wondered but were afraid to ask” submission box. It can be found [here](https://padlet.com/kuznetso/computer-questions-we-are-afraid-to-ask-wiba0xplqda3eqbr), and is always open for anonymous public submissions.

<div class="padlet-embed" style="border:1px solid rgba(0,0,0,0.1);border-radius:2px;box-sizing:border-box;overflow:hidden;position:relative;width:100%;background:#F4F4F4"><p style="padding:0;margin:0"><iframe src="https://padlet.com/embed/wiba0xplqda3eqbr" frameborder="0" allow="camera;microphone;geolocation" style="width:100%;height:608px;display:block;padding:0;margin:0"></iframe></p><div style="display:flex;align-items:center;justify-content:end;margin:0;height:28px"><a href="https://padlet.com?ref=embed" style="display:block;flex-grow:0;margin:0;border:none;padding:0;text-decoration:none" target="_blank"><div style="display:flex;align-items:center;"><img src="https://padlet.net/embeds/made_with_padlet_2022.png" width="114" height="28" style="padding:0;margin:0;background:0 0;border:none;box-shadow:none" alt="Made with Padlet"></div></a></div></div>
  
<br>

### Some references and materials

This will be a (hopefully constantly growing) list of resources that have had the most impact on me personally in changing my perspective on computational thinking and digital literacy education.

#### Books
+ **Electronic Life: How to Think About Computers (1984) by Michael Crichton** – a very accessible explainer demystifying early personal computers to amateur users in the 80s
+ **The Elements of Computing Systems (2005)** by Noam Nisan and Shimon Schocken – learning computer science through building a simple physical computer from scratch

<br>

#### Online courses and explainers
+ **Chris Woodford’s chapter on Computers from *Explain That Stuff*** - [https://www.explainthatstuff.com/howcomputerswork.html](https://www.explainthatstuff.com/howcomputerswork.html)

<br>

#### Cool people
+ **Nicky Case** – [https://ncase.me/](https://ncase.me/)
+ **Gillian Smith** – [https://www.wpi.edu/people/faculty/gmsmith](https://www.wpi.edu/people/faculty/gmsmith)

<br>
<br>
> Stay tuned for more updates on this over Summer and Fall!
